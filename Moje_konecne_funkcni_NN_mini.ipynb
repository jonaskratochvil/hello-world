{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moje_konecne_funkcni_NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jonaskratochvil/hello-world/blob/master/Moje_konecne_funkcni_NN_mini.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "hyuKVPe1X3PM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import random \n",
        "\n",
        "from scipy.stats import truncnorm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aGn8-XpiX5Wi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def stable_softmax(x):\n",
        "  exps = np.exp(X - np.max(X))\n",
        "  return exps / np.sum(exps)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KHZG-7zYwK7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
        "    return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M-M6o4q8YBDd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "  \n",
        "  def __init__(self, n_in_nodes, n_hidden_nodes, n_out_nodes, learning_rate):\n",
        "    \n",
        "    self.n_in_nodes = n_in_nodes\n",
        "    self.n_hidden_nodes = n_hidden_nodes\n",
        "    self.n_out_nodes = n_out_nodes\n",
        "    self.learning_rate = learning_rate\n",
        "    self.weights_in = np.random.randn(n_hidden_nodes, n_in_nodes)\n",
        "    self.weights_out = np.random.randn(n_out_nodes, n_hidden_nodes)\n",
        "    self.bias_in = np.random.randn(n_hidden_nodes,1)\n",
        "    self.bias_out = np.random.randn(n_out_nodes,1)\n",
        "  \n",
        "  def train(self, input_data, input_labels):\n",
        "    \n",
        "    # Transponovani dat z 4x3 na 3x4 -> weights jsou 4x3, 1x4\n",
        "    \n",
        "    input_data = np.array(input_data, ndmin = 2).T\n",
        "    input_labels = np.array(input_labels, ndmin = 2).T\n",
        "    \n",
        "    # Forward propagate 4x3 x 3x4 -> 4x4 \n",
        "    \n",
        "    l0 = sigmoid(np.dot(self.weights_in, input_data)+self.bias_in)\n",
        "    \n",
        "    # 1x4 x 4x4 -> 1x4\n",
        "    \n",
        "    l1 = sigmoid(np.dot(self.weights_out, l0)+self.bias_out)\n",
        "    \n",
        "    # self.output_error_L2 = 1/2*(input_data - l1) **2\n",
        "    # d1 = l1 - input_data * (l1)(1-l1) -> tady je ten term derivace sigmoidu ktery spomaluje learning\n",
        "    \n",
        "    self.output_error_CE = -(input_labels * np.log(l1) + (1-input_labels) * np.log(1-l1))\n",
        "    \n",
        "    # dal jsem derivaci square loss kdyz napr 0.8 - 0 -> zaporny learning rate da to znamenko tak jak chci\n",
        "    \n",
        "    # kdyz 0.1 - 1 tak zase ten learning rate to hodi tam kam chci\n",
        "    \n",
        "    # Backpropagate -> deltas in first and zero layer from Nielsen formula\n",
        "    \n",
        "    # i d1 nyni derivace CE funkce kterou se vymaze ta derivace sigmoidu -> opravdu je videt rozdil!!!\n",
        "    \n",
        "    d1 = -input_labels*(1-l1) + (1-input_labels)*l1\n",
        "    d0 = np.dot(self.weights_out.T,d1)*(l0*(1-l0))\n",
        "    \n",
        "    # Weight update change from Nielsen formula to np.dot(delta1, output0.T)\n",
        "    \n",
        "    self.dw_out = np.dot(d1,l0.T)\n",
        "    self.dw_in = np.dot(d0,input_data.T)\n",
        "    \n",
        "    self.db_out = d1\n",
        "    self.db_in = d0\n",
        "    \n",
        "  def SGD(self, X, y, epochs, batch_size):\n",
        "    \n",
        "    batch_w_in_update = np.zeros((self.n_hidden_nodes, self.n_in_nodes), dtype=int)\n",
        "    batch_w_out_update = np.zeros((self.n_out_nodes, self.n_hidden_nodes), dtype=int)\n",
        "    batch_b_in_update = np.zeros((self.n_hidden_nodes,1), dtype=int)\n",
        "    batch_b_out_update = np.zeros((self.n_out_nodes,1), dtype=int)\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "      \n",
        "      # shuffle randomly data before start of each epoch\n",
        "      \n",
        "      data_shuffle = [i for i in range(X.shape[0])]\n",
        "      data_shuffle = random.sample(data_shuffle, len(data_shuffle))\n",
        "\n",
        "      X = np.array([X[i] for i in data_shuffle])\n",
        "      y = np.array([y[i] for i in data_shuffle])\n",
        "      \n",
        "      for minibatch in range(0,X.shape[0],batch_size):\n",
        "        \n",
        "        for example in range(minibatch,minibatch+batch_size):\n",
        "          \n",
        "          # Append weight and biases gradients\n",
        "          \n",
        "          self.train(X[example],y[example])\n",
        "          batch_w_in_update = batch_w_in_update + self.dw_in\n",
        "          batch_w_out_update = batch_w_out_update + self.dw_out\n",
        "          batch_b_in_update = batch_b_in_update + self.db_in\n",
        "          batch_b_out_update = batch_b_out_update + self.db_out\n",
        "        \n",
        "        # Update current weights to new ones with minibatch update\n",
        "        \n",
        "        self.weights_in = self.weights_in - self.learning_rate/batch_size * batch_w_in_update \n",
        "        self.weights_out = self.weights_out - self.learning_rate/batch_size * batch_w_out_update\n",
        "        \n",
        "        self.bias_in = self.bias_in - self.learning_rate/batch_size * batch_b_in_update \n",
        "        self.bias_out = self.bias_out - self.learning_rate/batch_size * batch_b_out_update\n",
        "        \n",
        "        batch_w_in_update = np.zeros((self.n_hidden_nodes, self.n_in_nodes), dtype=int)\n",
        "        batch_w_out_update = np.zeros((self.n_out_nodes, self.n_hidden_nodes), dtype=int)\n",
        "        batch_b_in_update = np.zeros((self.n_hidden_nodes,1), dtype=int)\n",
        "        batch_b_out_update = np.zeros((self.n_out_nodes,1), dtype=int)\n",
        "        \n",
        "      if (epoch % 20000) == 0:\n",
        "\n",
        "        print (\"epoch:\" + str(epoch) + \" error: \" + str(np.mean(np.abs(self.output_error_CE))))\n",
        "    \n",
        "  def run(self, test_data):\n",
        "     \n",
        "    test_data = np.array(test_data, ndmin = 2).T\n",
        "    l0 = sigmoid(np.dot(self.weights_in, test_data) + self.bias_in)\n",
        "    l1 = sigmoid(np.dot(self.weights_out, l0) + self.bias_out)\n",
        "\n",
        "    return l1\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kXxfKrg_bcIV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = NeuralNetwork(3, 4, 1, 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P3wAPUaublEB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = np.array([[0,0,1],\n",
        "             [0,1,1],\n",
        "             [1,0,1],\n",
        "             [1,1,1],])\n",
        "\n",
        "y = np.array([[0,0,1,1]]).T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "byRf8R5NKlPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "da31ba1c-f1f4-4c6d-8ef1-6415c737e1e9"
      },
      "cell_type": "code",
      "source": [
        "net.SGD(X,y,200000,2)"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0 error: 0.5447801692479085\n",
            "epoch:20000 error: 0.2364271461453347\n",
            "epoch:40000 error: 0.05006288139600575\n",
            "epoch:60000 error: 0.03709872342101401\n",
            "epoch:80000 error: 0.017374361830095466\n",
            "epoch:100000 error: 0.018546471176214486\n",
            "epoch:120000 error: 0.010387390881346955\n",
            "epoch:140000 error: 0.00900982850236944\n",
            "epoch:160000 error: 0.009923341906941593\n",
            "epoch:180000 error: 0.008683635833432296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tjr5-LKJYOCO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "d72acb2b-80ca-452e-e173-0e32c6705b06"
      },
      "cell_type": "code",
      "source": [
        "print(net.weights_out)\n",
        "\n",
        "print(net.weights_in)"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.30590105  1.66158096 -3.42337182 -1.60904191]]\n",
            "[[-2.44224578 -0.07899151  0.9947154 ]\n",
            " [ 1.07269503 -0.1453175   0.39861019]\n",
            " [-3.32550781  0.48899724 -1.21814016]\n",
            " [-1.89712127 -1.4544356  -0.51458949]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ek99ndaab8JV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e021c25-d306-463e-f9ed-ea817da7afdd"
      },
      "cell_type": "code",
      "source": [
        "point = np.array([[0,0,1]])\n",
        "\n",
        "net.run(point)"
      ],
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00760154]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 365
        }
      ]
    },
    {
      "metadata": {
        "id": "FJQbhunFh0ZA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(100000):\n",
        "  net.train(X,y)\n",
        "  if (i % 10000) == 0:\n",
        "\n",
        "      print (\"iteration:\" + str(i) + \" accuracy: \" + str(1 - np.mean(np.abs(net.output_error))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mz_F6RyXYgi-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "324c33ed-753e-4b84-8ecb-eb15e9233b52"
      },
      "cell_type": "code",
      "source": [
        "v = [\"bear\", \"lion\", \"dog\"]\n",
        "\n",
        "z = []\n",
        "\n",
        "for i in v:\n",
        "  z.append(i)\n",
        "  \n",
        "\n",
        "ind_list = [i for i in range(len(z))]\n",
        "\n",
        "ind_list = random.sample(ind_list, len(ind_list))\n",
        "\n",
        "z = [z[i] for i in ind_list]\n",
        "\n",
        "print(z)\n",
        "\n",
        "\n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['lion', 'dog', 'bear']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TZNzC6HZYhE_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cross_entropy_loss = -(1.0/intput_data.T.shape[0]) * np.sum(input_labels*np.log(l1) + (1-input_labels)*np.log(1-l1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KOcaBdUMYhCP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qoJqxFaJgvhN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST.data/\", one_hot = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n8VQDJwPEFG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2faaef82-b814-4238-d330-03e9689974fc"
      },
      "cell_type": "code",
      "source": [
        "print(mnist.train.labels.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WTNOpTUEEPvw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net_mnist = NeuralNetwork(784, 10 , 10, 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TOq0KdB9EgKi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "  net_mnist.train(mnist.train.images,mnist.train.labels)\n",
        "  \n",
        "  if i % 100 == 0:\n",
        "    \n",
        "    print (\"iteration:\" + str(i) + \" accuracy: \" + str(1 - np.mean(np.abs(net_mnist.output_error))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "miC632zwEyio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "101c2135-5860-4f7e-a89d-f50177d1fad6"
      },
      "cell_type": "code",
      "source": [
        "print(mnist.test.labels[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qv8T7sGBHfIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net_mnist.run(mnist.test.images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bmQG53kmHpWZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}